install.packages("factoextra")
library(knitr)
library(rmdformats)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
datos <- read.table("../datos/SAheart.csv", sep = ";", dec = ".", header = T)
str(datos)
res<-PCA(datos[,-c(5,10)], scale.unit=TRUE, ncp=5, graph = FALSE)
library("FactoMineR")
library("FactoMineR")
library("factoextra")
res<-PCA(datos[,-c(5,10)], scale.unit=TRUE, ncp=5, graph = FALSE)
plot(res, axes=c(1, 2), choix="ind",col.ind="red",new.plot=TRUE,select="cos2 0.05")
plot(res, axes=c(1, 2),
choix="var",col.var="blue",new.plot=TRUE,select="cos2 0.05")
fviz_pca_biplot(modelo,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema)
# Valores de los gráficos por defecto
mi.tema <- theme_grey() + theme(panel.border = element_rect(fill = NA,color = "black"), plot.title = element_text(hjust = 0.5))
fviz_pca_var(res,col.var="steelblue", select.var = list(cos2 = 0.05),ggtheme = mi.tema)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema, select="cos2 0.05")
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema, select="cos2 0.05")
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",ggtheme = mi.tema, select="cos2 0.05")
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",select.ind = list(cos2 = 0.1),ggtheme = mi.tema)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",select.ind = list(cos2 = 0.05),ggtheme = mi.tema)
famhist.Present <- as.numeric(datos$famhist == "Present")
famhist.Absent <- as.numeric(datos$famhist == "Absent")
chd.Si <- as.numeric(datos$chd == "Si")
chd.No <- as.numeric(datos$chd == "No")
datos2<-datos[,-c(5,10)]
datos2<-cbind(datos2,famhist.Present)
datos2<-cbind(datos2,famhist.Absent)
datos2<-cbind(datos2,chd.Si)
datos2<-cbind(datos2,chd.No)
res<-PCA(datos2, scale.unit=TRUE, ncp=5, graph = FALSE)
plot(res, axes=c(1, 2), choix="ind", col.ind="red",new.plot=TRUE)
plot(res, axes=c(1, 2), choix="var", col.var="blue",new.plot=TRUE)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",select.ind = list(cos2 = 0.05),ggtheme = mi.tema)
datos <- read.table("..\datos\DeudaCredito.csv", sep=",", dec = ".", header = TRUE )
datos <- read.table("../datos/DeudaCredito.csv", sep=",", dec = ".", header = TRUE )
View(datos)
datos <- read.table("../datos/DeudaCredito.csv", sep=",", dec = ".", header = TRUE, row.names = T)
datos <- read.table("../datos/DeudaCredito.csv", sep=",", dec = ".", header = TRUE, row.names = 1)
str(datos)
# Residual Sum of Square (RSS)
RSS <- function(Pred,Real) {
ss <- sum((Real-Pred)^2)
return(ss)
}
# NumPred es el número total de predictores por eso se resta 1 (que es realidad sumar 1)
RSE<-function(Pred,Real,NumPred) {
N<-length(Real)-NumPred-1  # <- length(Real)-(NumPred+1)
ss<-sqrt((1/N)*RSS(Pred,Real))
return(ss)
}
MSE <- function(Pred,Real) {
N<-length(Real)
ss<-(1/N)*RSS(Pred,Real)
return(ss)
}
error.relativo <- function(Pred,Real) {
ss<-sum(abs(Real-Pred))/sum(abs(Real))
return(ss)
}
# Funciones para desplegar precisión
indices.precision <- function(real, prediccion,cantidad.variables.predictoras) {
return(list(error.cuadratico = MSE(prediccion,real),
raiz.error.cuadratico = RSE(prediccion,real,cantidad.variables.predictoras),
error.relativo = error.relativo(prediccion,real),
correlacion = as.numeric(cor(prediccion,real))))
}
# Gráfico de dispersión entre el valor real de la variable a predecir y la predicción del modelo.
plot.real.prediccion <- function(real, prediccion, modelo = "") {
g <- ggplot(data = data.frame(Real = real, Prediccion = as.numeric(prediccion)), mapping = aes(x = Real, y = Prediccion)) +
geom_point(size = 1, col = "dodgerblue3") +
labs(title = paste0("Real vs Predicción", ifelse(modelo == "", "", paste(", con", modelo))),
x = "Real",
y = "Predicción")
return(g)
}
library(pls)
datos$Genero <- as.factor(datos$Genero)
datos <- read.table("../datos/DeudaCredito.csv", dec = ".", sep = ",", header = T, row.names = 1)
datos <- dummy_cols(datos, select_columns = c("Genero","Estudiante","Casado","Etnicidad"),remove_selected_columns = T)
library(fastDummies)
datos <- read.table("../datos/DeudaCredito.csv", dec = ".", sep = ",", header = T, row.names = 1)
datos <- dummy_cols(datos, select_columns = c("Genero","Estudiante","Casado","Etnicidad"),remove_selected_columns = T)
str(datos)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
modelo.pcr <- pcr(Balance~., data = datos, scale = TRUE, validation = "CV")
summary(modelo.pcr)
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
library(pls)
modelo.pcr <- pcr(Balance~., data = datos, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
modelo.plsr <- plsr(Balance~., data = ttesting, scale = TRUE, validation = "CV")
summary(modelo.plsr)
#  Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.plsr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Gráfico Con ggplot
ggplot(data = data.frame(Componentes = 0:(length(RMSE.CV) - 1), Error = RMSE.CV), mapping = aes(x = Componentes, y = Error)) +
geom_vline(xintercept = componentes.usados, color = "#858585") +
geom_point(size = 1, col = "dodgerblue3") +
geom_line(size = 0.5, col = "dodgerblue3") +
labs(title = "RMSE según Número de Componentes",
x = "Número de Componentes",
y = "RMSE")
modelo.plsr <- plsr(Balance~., data = ttesting, scale = TRUE, validation = "CV")
#  Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.plsr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.plsr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.plsr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.plsr
modelo.pcr <- pcr(Balance~., data = datos, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
RMSE.CV
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
RMSE.CV
# Gráfico de varianza explicada en los predictores según componentes usados
var.explicada <- cumsum(explvar(modelo.plsr)) / 100
var.explicada
RMSE.CV
componentes.usados <- 3  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
componentes.usados <- 6  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
componentes.usados <- 9  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
componentes.usados <- 5  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
componentes.usados <- 3  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
datos <- read.table("../datos/AsientosNinno.csv", dec = ".", sep = ";",header = T, stringsAsFactors = T)[,-1]
datos$CalidadEstant <- factor(datos$CalidadEstant,levels = c("Malo","Medio","Bueno"), ordered=TRUE)
str(datos)
datos <- dummy_cols(datos, select_columns = c("CalidadEstant"),remove_selected_columns = T)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
#elimino las variables
taprendizaje <- taprendizaje[,-c(4,13)]
ttesting <- ttesting[,-c(4,13)]
library(pls)
modelo.pcr <- pcr(Ventas~., data = datos, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
datos <- read.table("../datos/AsientosNinno.csv", dec = ".", sep = ";",header = T, stringsAsFactors = T)[,-1]
datos$CalidadEstant <- factor(datos$CalidadEstant,levels = c("Malo","Medio","Bueno"), ordered=TRUE)
str(datos)
datos <- dummy_cols(datos, select_columns = c("CalidadEstant"),remove_selected_columns = T)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
#elimino las variables
taprendizaje <- taprendizaje[,-c(4,13)]
ttesting <- ttesting[,-c(4,13)]
library(pls)
modelo.pcr <- pcr(Ventas~., data = datos, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
modelo.plsr <- plsr(Ventas~., data = ttesting, scale = TRUE, validation = "CV")
#  Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.plsr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.plsr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.plsr <- indices.precision(ttesting$Ventas, prediccion,numero.predictoras)
pre.plsr
modelo.pcr <- pcr(Ventas~., data = datos, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
library(pls)
modelo.pcr <- pcr(Ventas~., data = taprendizaje, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Ventas, prediccion,numero.predictoras)
pre.pcr
library(fastDummies)
datos <- read.table("../datos/DeudaCredito.csv", dec = ".", sep = ",", header = T, row.names = 1)
datos <- dummy_cols(datos, select_columns = c("Genero","Estudiante","Casado","Etnicidad"),remove_selected_columns = T)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
# Residual Sum of Square (RSS)
RSS <- function(Pred,Real) {
ss <- sum((Real-Pred)^2)
return(ss)
}
# NumPred es el número total de predictores por eso se resta 1 (que es realidad sumar 1)
RSE<-function(Pred,Real,NumPred) {
N<-length(Real)-NumPred-1  # <- length(Real)-(NumPred+1)
ss<-sqrt((1/N)*RSS(Pred,Real))
return(ss)
}
MSE <- function(Pred,Real) {
N<-length(Real)
ss<-(1/N)*RSS(Pred,Real)
return(ss)
}
error.relativo <- function(Pred,Real) {
ss<-sum(abs(Real-Pred))/sum(abs(Real))
return(ss)
}
# Funciones para desplegar precisión
indices.precision <- function(real, prediccion,cantidad.variables.predictoras) {
return(list(error.cuadratico = MSE(prediccion,real),
raiz.error.cuadratico = RSE(prediccion,real,cantidad.variables.predictoras),
error.relativo = error.relativo(prediccion,real),
correlacion = as.numeric(cor(prediccion,real))))
}
# Gráfico de dispersión entre el valor real de la variable a predecir y la predicción del modelo.
plot.real.prediccion <- function(real, prediccion, modelo = "") {
g <- ggplot(data = data.frame(Real = real, Prediccion = as.numeric(prediccion)), mapping = aes(x = Real, y = Prediccion)) +
geom_point(size = 1, col = "dodgerblue3") +
labs(title = paste0("Real vs Predicción", ifelse(modelo == "", "", paste(", con", modelo))),
x = "Real",
y = "Predicción")
return(g)
}
library(pls)
modelo.pcr <- pcr(Balance~., data = taprendizaje, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
modelo.plsr <- plsr(Balance~., data = taprendizaje, scale = TRUE, validation = "CV")
#  Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.plsr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.plsr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.plsr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.plsr
modelo.pcr <- pcr(Balance~., data = taprendizaje, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
RMSE.CV
# Gráfico de varianza explicada en los predictores según componentes usados
var.explicada <- cumsum(explvar(modelo.plsr)) / 100
var.explicada
componentes.usados <- 3  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Balance, prediccion,numero.predictoras)
pre.pcr
datos <- read.table("../datos/AsientosNinno.csv", dec = ".", sep = ";",header = T, stringsAsFactors = T)[,-1]
datos$CalidadEstant <- factor(datos$CalidadEstant,levels = c("Malo","Medio","Bueno"), ordered=TRUE)
str(datos)
datos <- dummy_cols(datos, select_columns = c("CalidadEstant"),remove_selected_columns = T)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
#elimino las variables
taprendizaje <- taprendizaje[,-c(4,13)]
ttesting <- ttesting[,-c(4,13)]
library(pls)
modelo.pcr <- pcr(Ventas~., data = taprendizaje, scale = TRUE, validation = "CV")
# Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.pcr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.pcr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.pcr <- indices.precision(ttesting$Ventas, prediccion,numero.predictoras)
pre.pcr
modelo.plsr <- plsr(Ventas~., data = ttesting, scale = TRUE, validation = "CV")
#  Selección automática y manual de la cantidad de componentes a usar según RMSE
# Automática
RMSE.CV <- RMSEP(modelo.plsr)$val[1, 1, ]
componentes.usados <- which.min(RMSE.CV) - 1  # RMSE.CV considera 0 componentes principales, por eso se resta 1.
componentes.usados
# Predicción
prediccion <- predict(modelo.plsr, ttesting, ncomp = componentes.usados)
# Medición de precisión
numero.predictoras <- dim(datos)[2]-1
pre.plsr <- indices.precision(ttesting$Ventas, prediccion,numero.predictoras)
pre.plsr
errores <- rbind(as.data.frame(pre.pcr),as.data.frame(pre.plsr))
rownames(errores) <- c("Regresión ACP"," Regresión MCP")
errores
errores %>%
filter(raiz.error.cuadratico == min(errores$raiz.error.cuadratico))
library(dplyr)
errores <- rbind(as.data.frame(pre.pcr),as.data.frame(pre.plsr))
rownames(errores) <- c("Regresión ACP"," Regresión MCP")
errores
errores %>%
filter(raiz.error.cuadratico == min(errores$raiz.error.cuadratico))
datos <- read.table("../datos/SpotifyTop2018_40_V2.csv", sep = ",", dec = ".", header = T)
str(datos)
datos$time_signature <- as.factor(datos$time_signature)
summary(datos)
library(ggplot2)
ggplot(datos, aes(x= energy, y = tempo))+
geom_point()
boxplot(datos)
library(corrplot)
matriz.correlacion<-cor(datos[,-11])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(matriz.correlacion, method="shade", shade.col=NA, tl.col="black", tl.srt=45,
col=col(200), addCoef.col="black", order="AOE")
library("FactoMineR")
library("factoextra")
res<-PCA(datos[,-11], scale.unit=TRUE, ncp=5, graph = FALSE)
cos2.ind<-(res$ind$cos2[,1]+res$ind$cos2[,2])*100
plot(res, axes=c(1, 2), choix="ind",col.ind="red",new.plot=TRUE,select="cos2 0.05")
# Valores de los gráficos por defecto
mi.tema <- theme_grey() + theme(panel.border = element_rect(fill = NA,color = "black"), plot.title = element_text(hjust = 0.5))
fviz_pca_var(res,col.var="steelblue", select.var = list(cos2 = 0.05),ggtheme = mi.tema)
fviz_pca_var(res,col.var="steelblue", select.var = list(cos2 = 0.05),ggtheme = mi.tema)
fviz_pca_biplot(res,col.var = "#2E9FDF",col.ind = "#696969",select.ind = list(cos2 = 0.05),ggtheme = mi.tema)
