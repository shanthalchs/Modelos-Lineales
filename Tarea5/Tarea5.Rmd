---
title: "Tarea 5 - Modelos Lineales"
author: "Shanthal Chavarría"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged 
    highlight: kate
    toc: TRUE
    toc_float: TRUE
---


```{r setup, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

```{r,echo=FALSE}
# Residual Sum of Square (RSS)
RSS <- function(Pred,Real) {
  ss <- sum((Real-Pred)^2)
  return(ss)
}
RSE<-function(Pred,Real,NumPred) {
  N<-length(Real)-NumPred-1  # <- length(Real)-(NumPred+1)
  ss<-sqrt((1/N)*RSS(Pred,Real))
  return(ss)
}
MSE <- function(Pred,Real) {
  N<-length(Real)
  ss<-(1/N)*RSS(Pred,Real)
  return(ss)
}
error.relativo <- function(Pred,Real) {
  ss<-sum(abs(Real-Pred))/sum(abs(Real))
  return(ss)
}

# Funciones para desplegar precisión
indices.precision <- function(real, prediccion,cantidad.variables.predictoras) {
  return(list(error.cuadratico = MSE(prediccion,real),
              raiz.error.cuadratico = RSE(prediccion,real,cantidad.variables.predictoras),
              error.relativo = error.relativo(prediccion,real),
              correlacion = as.numeric(cor(prediccion,real))))
}


# Gráfico de dispersión entre el valor real de la variable a predecir y la predicción del modelo.
plot.real.prediccion <- function(real, prediccion, modelo = "") {
  g <- ggplot(data = data.frame(Real = real, Prediccion = as.numeric(prediccion)), mapping = aes(x = Real, y = Prediccion)) +
    geom_point(size = 1, col = "dodgerblue3") +
    labs(title = paste0("Real vs Predicción", ifelse(modelo == "", "", paste(", con", modelo))),
         x = "Real",
         y = "Predicción")
  return(g)
}
```

```{r, echo=FALSE}
Confusion <- function(MC){
  VN <- MC[1,1]
  FN <- MC[2,1]
  VP <- MC[2,2]
  FP <- MC[1,2]
  
  PG <- (VN + VP)/(VN + FP + FN + VP)
  EG <- 1 - PG
  PP <- VP/(FN + VP)
  PN <- VN/(FP + VN)
  FP <- FP/(VN + FP)
  FN <- FN/(VP + FN)
  AP <- VP/(FP + VP)
  AN <- VN/(VN + FN)
  
  Respuesta <- list(PG = PG,EG = EG, PP = PP,PN = PN,FP = FP,FN=FN,AP=AP,AN=AN)
  
  names(Respuesta) <- c("Precision Global", "Error Global","Precision Positiva", "Precision Negativa", "Falsos Positivos", "Falsos Negativos", "Asertividad Positiva" , "Asertividad Negativa")
  
  return(Respuesta)
}
```

# Pregunta 1: __[10 puntos]__ En este ejercicio vamos a usar la tabla de datos `wine.csv`, que contiene variantes del vino “Vinho Verde”. Los datos incluyen variables de pruebas fisicoquímicas y sensoriales realizadas a dicho vino. 

La tabla contiene 1599 filas y 12 columnas, las cuales se explican a continuación.

Para esto realice lo siguiente:

## 1. Cargue la tabla de datos `wine.csv` en `R`.

```{r}
datos <- read.table("datos/wine.csv", sep = ",", dec = ".", header = T, stringsAsFactors = T)
```

## 2. Usando el comando sample de `R` genere al azar una tabla de testing con una 20 % de los datos y con el resto de los datos genere una tabla de aprendizaje.

```{r}
filas <- dim(datos)[1] 
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
```

## 3. Use el método de los `SVM` con `traineR` para generar un modelo predictivo para la tabla de aprendizaje. Pruebe con todos los kernel (núcleos) `linear`, `polynomial`, `radial basis` y `sigmoid` hasta encontrar el que minimiza el error global.


### Linear

```{r}
library(traineR)

modelo.linear <- train.svm(tipo~., data = taprendizaje, kernel = "linear")
prediccion.linear <- predict(modelo.linear, ttesting , type = "class")

MC.Linear <- confusion.matrix(ttesting, prediccion.linear)
linear <- general.indexes(mc = MC.Linear)
linear
```

### Polynomial

```{r}
modelo.polynomial <- train.svm(tipo~., data = taprendizaje, kernel = "polynomial")
prediccion.polynomial <- predict(modelo.polynomial, ttesting , type = "class")
MC.polynomial <- confusion.matrix(ttesting, prediccion.polynomial)
polynomial <- general.indexes(mc = MC.polynomial)
polynomial
```

### Radial

```{r}
modelo.radial <- train.svm(tipo~., data = taprendizaje, kernel = "radial")
prediccion.radial <- predict(modelo.radial, ttesting , type = "class")
MC.radial <- confusion.matrix(ttesting, prediccion.radial)
radial <- general.indexes(mc = MC.radial)
radial
```

### Sigmoid

```{r}
modelo.sigmoid <- train.svm(tipo~., data = taprendizaje, kernel = "sigmoid")
prediccion.sigmoid <- predict(modelo.sigmoid, ttesting , type = "class")
MC.sigmoid <- confusion.matrix(ttesting, prediccion.sigmoid)
sigmoid <- general.indexes(mc = MC.sigmoid)
sigmoid
```

## 4. Usando Redes Neuronales con el paquete `traineR` genere un modelo predictivo para la tabla de aprendizaje. Pruebe modificar los parámetros del método hasta encontrar el que minimiza el error global.

```{r}
modelo.nnet <- train.nnet(tipo~. , data = taprendizaje, size = 4, maxit = 1000)

prediccion.nnet <- predict(modelo.nnet, ttesting, type = "class")

MC.nnet <- confusion.matrix(ttesting,prediccion.nnet)

redesNeuronales <- general.indexes(mc=MC.nnet)
redesNeuronales
```

## 5. Construya un DataFrame de manera que en cada una de las filas aparezca un modelo predictivo y en las columnas aparezcan los índices *Precisión Global, Error Global, Precisión Positiva (PP), Precisión Negativa (PN), Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (AN)*. ¿Cuál de los modelos es mejor para estos datos? (incluya todos los métodos que hemos estudiando en el curso).

```{r}
library(dplyr)

precisiones <- rbind(as.data.frame(Confusion(linear$confusion.matrix)),as.data.frame(Confusion(polynomial$confusion.matrix)),as.data.frame(Confusion(radial$confusion.matrix)),as.data.frame(Confusion(sigmoid$confusion.matrix)),as.data.frame(Confusion(redesNeuronales$confusion.matrix)))


tablaC <- read.table("Tabla Comparativa wine2.csv",dec = ".",sep = "," , header = T)

tablaC <- rbind(precisiones,tablaC)

rownames(tablaC) <- c("SVM.linear","SVM.polynomial","SVM.radial","SVM.sigmoid","Redes Neuronales","Árboles de Decisión", "Bosques Aleatorios", "ADA Boosting", "XG Boosting","KNN.rectangular", "KNN.triangular", "KNN.epanechnikov", "KNN.biweight", "KNN.triweight", "KNN.cos",
"KNN.inv", "KNN.gaussian","KNN.optimal")



tablaC %>%
  arrange(desc(Precision.Global))




write.csv(tablaC,"Tabla Comparativa wine3.csv", row.names = FALSE)
tablaC


```
El modelo con la mejor Precisión Global fue KNN con kernel `inv`. Debido a que la Precisión Negativa y Precisión Positiva es bastante buena nos quedamos con este como el mejor modelo.

# Pregunta 2: [10 puntos] Suponga que somos contratados por el banco y se nos pide volver a predecir el monto promedio de deuda en tarjeta de crédito de una cartera de clientes relativamente nuevos, basado en otra cartera de comportamiento y estructura similar de la cual sí se tiene información de deuda en tarjeta de crédito. En este ejercicio hacemos uso de la tabla de datos `DeudaCredito.csv` que contiene información de los clientes en una de las principales carteras de crédito del banco, e incluye variables que describen cada cliente tanto dentro del banco como fuera de este.

Cargue la tabla de datos en `R`, asegúrese que las variables se están leyendo de forma correcta.
Recodifique variables en caso de que sea necesario, tome para entrenamiento un 80 % de la tabla de datos. Realice lo siguiente:

```{r}
datos <- read.table("datos/DeudaCredito.csv", dec = ".", sep = ",", header = T, stringsAsFactors = T )[,-1]

str(datos)

numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1] 
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
```
## 1. Ejecute un modelo de regresión con `SVM` con todos los kernels disponibles e interprete las medidas de error del mejor de esos modelos.


### Linear

```{r}
library(traineR)

modelo.linear <- train.svm(Balance~., data = taprendizaje, kernel = "linear")
prediccion.linear <- predict(modelo.linear, ttesting)

linear <- indices.precision(ttesting$Balance ,prediccion.linear$prediction,numero.predictoras)
linear
```

### Polynomial

```{r}
modelo.polynomial <- train.svm(Balance~., data = taprendizaje, kernel = "polynomial")
prediccion.polynomial <- predict(modelo.polynomial, ttesting)

polynomial <- indices.precision(ttesting$Balance ,prediccion.polynomial$prediction,numero.predictoras)
polynomial
```

### Radial

```{r}
modelo.radial <- train.svm(Balance~., data = taprendizaje, kernel = "radial")
prediccion.radial <- predict(modelo.radial, ttesting)

radial <- indices.precision(ttesting$Balance ,prediccion.radial$prediction,numero.predictoras)
radial
```

### Sigmoid

```{r}
modelo.sigmoid <- train.svm(Balance~., data = taprendizaje, kernel = "sigmoid")
prediccion.sigmoid <- predict(modelo.sigmoid, ttesting)

sigmoid <- indices.precision(ttesting$Balance ,prediccion.sigmoid$prediction,numero.predictoras)
sigmoid
```

El mejor resultado lo obtuvo `radial`, con una correlación de 98.4% y un error en promedio de 12%. Em promedio se equivocó por 95.35.

## 2. ¿Qué observa en los gráficos de dispersión que muestra los valores reales contra la predicción de cada modelo? ¿Qué desventajas o ventajas puede observar en cada modelo? Explique.

### Linear

```{r}
library(ggplot2)
g <- plot.real.prediccion(ttesting$Balance, prediccion.linear$prediction , modelo = "SVM - Linear")

g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

### polynomial

```{r}
g <- plot.real.prediccion(ttesting$Balance, prediccion.polynomial$prediction , modelo = "SVM - Polynomial")

g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

### radial

```{r}
g <- plot.real.prediccion(ttesting$Balance, prediccion.radial$prediction , modelo = "SVM - Radial")

g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

### Sigmoid

```{r}
g <- plot.real.prediccion(ttesting$Balance, prediccion.sigmoid$prediction , modelo = "SVM - Sigmoid")

g + geom_smooth(method = lm, size = 0.4, color = "red", se = FALSE)
```

## 3. Corra un modelo de redes neuronales usando 2 capas ocultas con 4 y 3 neuronas respectivamente. Ajuste los parámetros hasta que el modelo alcance convergencia (puede iniciar con umbral de detención como 0.05 y número de iteraciones de 50000).

```{r}
medias <- sapply(taprendizaje, mean) 
desviaciones <- sapply(taprendizaje[,-c(7:10)], sd)
# Se estandarizan los datos, esto se debe hacer de training y testing
datos.aprendizaje  <- as.data.frame(scale(taprendizaje[,-c(7:10)], center = medias, scale = desviaciones))
datos.testing <- as.data.frame(scale(ttesting[,-c(7:10)], center = medias, scale = desviaciones))
# Generamos la fórmula
nombres <- colnames(datos.aprendizaje)
formula <- as.formula(paste("lpsa ~", paste(nombres[!nombres %in% c("lpsa")], collapse = " + ")))
```


```{r}
library(neuralnet)
library(traineR)
# 2 capas
modelo.nnet2 <- neuralnet(formula, data = taprendizaje, hidden = c( 4, 3), linear.output = TRUE, threshold = 0.05, stepmax = 1e+05) 
prediccion.nnet2 <- predict(modelo.nnet2,ttesting)

MC.nnet2 <- confusion.matrix(ttesting, prediccion.nnet2)

indices1 <- indices.general(MC.nnet2)
```

