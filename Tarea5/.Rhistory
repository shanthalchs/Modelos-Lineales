library(traineR)
numero.predictoras <- dim(datos)[2] - 1
# Calcula el modelo usando solo los datos de training
# Se deben guardar las medias y las desviaciones
medias <- sapply(taprendizaje, mean)
desviaciones <- sapply(taprendizaje, sd)
# Se estandarizan los datos, esto se debe hacer de training y testing
taprendizaje.e  <- as.data.frame(scale(taprendizaje, center = medias, scale = desviaciones))
ttesting.e <- as.data.frame(scale(ttesting, center = medias, scale = desviaciones))
# Generamos la fórmula
nombres <- colnames(taprendizaje.e)
formula <- as.formula(paste("Balance ~", paste(nombres[!nombres %in% c("Balance")], collapse = " + ")))
# Generamos modelo. No acepta la notación lpsa~.
# Los parámetros a modificar son hidden, threshold y stepmax
# hidden = c(6, 4, 3) => 3 capas ocultas una con 6 neuronas; otra con 4 neuronas y otra con 3 neuronas
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(4,3), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
# Primero se obtiene la predicción estandarizada
prediccion.nnet2 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
# Luego se calcula la predicción final "des-estandarizando" los resultados
prediccion.nnet2 <- prediccion.nnet2 * desviaciones["Balance"] + medias["Balance"]
# Medición de precisión
indices1 <- indices.precision(ttesting$Balance, prediccion.nnet2,numero.predictoras)
indices1
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(4,2), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
prediccion.nnet3 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
prediccion.nnet3 <- prediccion.nnet3 * desviaciones["Balance"] + medias["Balance"]
# Medición de precisión
indices3 <- indices.precision(ttesting$Balance, prediccion.nnet3,numero.predictoras)
indices3
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(4,3), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
prediccion.nnet4 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
prediccion.nnet4 <- prediccion.nnet4 * desviaciones["Balance"] + medias["Balance"]
# Medición de precisión
indices4 <- indices.precision(ttesting$Balance, prediccion.nnet4,numero.predictoras)
indices4
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(6,3), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
prediccion.nnet4 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
prediccion.nnet4 <- prediccion.nnet4 * desviaciones["Balance"] + medias["Balance"]
# Medición de precisión
indices4 <- indices.precision(ttesting$Balance, prediccion.nnet4,numero.predictoras)
indices4
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(8,4,2), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
prediccion.nnet5 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
prediccion.nnet5 <- prediccion.nnet5 * desviaciones["Balance"] + medias["Balance"]
indices5 <- indices.precision(ttesting$Balance, prediccion.nnet5,numero.predictoras)
indices5
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(9,6,3), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
prediccion.nnet6 <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Balance")])$net.result
prediccion.nnet6 <- prediccion.nnet6 * desviaciones["Balance"] + medias["Balance"]
# Medición de precisión
indices6 <- indices.precision(ttesting$Balance, prediccion.nnet6,numero.predictoras)
indices6
errores <- rbind(as.data.frame(linear),as.data.frame(polynomial),as.data.frame(radial),as.data.frame(sigmoid),as.data.frame(indices4))
rownames(errores) <- c("SVM.linear"," SVM.polynomial","SVM.radial","SVM.sigmoid", "NeuralNet 2 capas")
errores
errores %>%
filter(raiz.error.cuadratico == min(errores$raiz.error.cuadratico))
library(dplyr)
errores %>%
filter(raiz.error.cuadratico == min(errores$raiz.error.cuadratico))
datos <- read.table("../datos/AsientosNinno.csv", dec = ".", sep = ";",header = T, stringsAsFactors = T)[,-1]
datos$CalidadEstant <- factor(datos$CalidadEstant,levels = c("Malo","Medio","Bueno"), ordered=TRUE)
str(datos)
datos <- dummy_cols(datos, select_columns = c("CalidadEstant"),remove_selected_columns = T)
numero.predictoras <- dim(datos)[2] - 1
filas <- dim(datos)[1]
muestra <- sample(1:filas, floor(filas*0.20))
ttesting <- datos[muestra,]
taprendizaje <- datos[-muestra,]
#elimino las variables
taprendizaje <- taprendizaje[,-c(4,13)]
ttesting <- ttesting[,-c(4,13)]
library(traineR)
modelo.linear <- train.svm(Ventas~., data = taprendizaje, kernel = "linear")
prediccion.linear <- predict(modelo.linear, ttesting)
linear <- indices.precision(ttesting$Ventas ,prediccion.linear$prediction,numero.predictoras)
linear
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
modelo.polynomial <- train.svm(Ventas~., data = taprendizaje, kernel = "polynomial")
prediccion.polynomial <- predict(modelo.polynomial, ttesting)
polynomial <- indices.precision(ttesting$Ventas ,prediccion.polynomial$prediction,numero.predictoras)
polynomial
modelo.radial <- train.svm(Ventas~., data = taprendizaje, kernel = "radial")
prediccion.radial <- predict(modelo.radial, ttesting)
radial <- indices.precision(ttesting$Ventas ,prediccion.radial$prediction,numero.predictoras)
radial
modelo.sigmoid <- train.svm(Ventas~., data = taprendizaje, kernel = "sigmoid")
prediccion.sigmoid <- predict(modelo.sigmoid, ttesting)
sigmoid <- indices.precision(ttesting$Ventas ,prediccion.sigmoid$prediction,numero.predictoras)
sigmoid
library(neuralnet)
library(traineR)
numero.predictoras <- dim(datos)[2] - 1
# Calcula el modelo usando solo los datos de training
# Se deben guardar las medias y las desviaciones
medias <- sapply(taprendizaje, mean)
desviaciones <- sapply(taprendizaje, sd)
# Se estandarizan los datos, esto se debe hacer de training y testing
taprendizaje.e  <- as.data.frame(scale(taprendizaje, center = medias, scale = desviaciones))
ttesting.e <- as.data.frame(scale(ttesting, center = medias, scale = desviaciones))
# Generamos la fórmula
nombres <- colnames(taprendizaje.e)
formula <- as.formula(paste("Balance ~", paste(nombres[!nombres %in% c("Balance")], collapse = " + ")))
# Generamos la fórmula
nombres <- colnames(taprendizaje.e)
formula <- as.formula(paste("Ventas ~", paste(nombres[!nombres %in% c("Ventas")], collapse = " + ")))
library(neuralnet)
library(traineR)
numero.predictoras <- dim(datos)[2] - 1
# Calcula el modelo usando solo los datos de training
# Se deben guardar las medias y las desviaciones
medias <- sapply(taprendizaje, mean)
desviaciones <- sapply(taprendizaje, sd)
# Se estandarizan los datos, esto se debe hacer de training y testing
taprendizaje.e  <- as.data.frame(scale(taprendizaje, center = medias, scale = desviaciones))
ttesting.e <- as.data.frame(scale(ttesting, center = medias, scale = desviaciones))
# Generamos la fórmula
nombres <- colnames(taprendizaje.e)
formula <- as.formula(paste("Ventas ~", paste(nombres[!nombres %in% c("Ventas")], collapse = " + ")))
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(6,3), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
# Primero se obtiene la predicción estandarizada
prediccion.nnet <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Ventas")])$net.result
# Luego se calcula la predicción final "des-estandarizando" los resultados
prediccion.nnet <- prediccion.nnet * desviaciones["Ventas"] + medias["Ventas"]
# Medición de precisión
NNET <- indices.precision(ttesting$Ventas, prediccion.nnet,numero.predictoras)
NNET
library(neuralnet)
library(traineR)
numero.predictoras <- dim(datos)[2] - 1
# Calcula el modelo usando solo los datos de training
# Se deben guardar las medias y las desviaciones
medias <- sapply(taprendizaje, mean)
desviaciones <- sapply(taprendizaje, sd)
# Se estandarizan los datos, esto se debe hacer de training y testing
taprendizaje.e  <- as.data.frame(scale(taprendizaje, center = medias, scale = desviaciones))
ttesting.e <- as.data.frame(scale(ttesting, center = medias, scale = desviaciones))
# Generamos la fórmula
nombres <- colnames(taprendizaje.e)
formula <- as.formula(paste("Ventas ~", paste(nombres[!nombres %in% c("Ventas")], collapse = " + ")))
modelo.red <- neuralnet(formula, data = taprendizaje.e, hidden = c(4,2), linear.output = TRUE, threshold = 0.05, stepmax = 50000)
# Plotea la red
plot(modelo.red, rep = "best", col.entry = "red", col.out = "green", arrow.length = 0.2)
# Predicción
# Primero se obtiene la predicción estandarizada
prediccion.nnet <- neuralnet::compute(modelo.red, ttesting.e[, -which(colnames(ttesting.e) == "Ventas")])$net.result
# Luego se calcula la predicción final "des-estandarizando" los resultados
prediccion.nnet <- prediccion.nnet * desviaciones["Ventas"] + medias["Ventas"]
# Medición de precisión
NNET <- indices.precision(ttesting$Ventas, prediccion.nnet,numero.predictoras)
NNET
errores <- rbind(as.data.frame(linear),as.data.frame(polynomial),as.data.frame(radial),as.data.frame(sigmoid),as.data.frame(NNET))
rownames(errores) <- c("SVM.linear"," SVM.polynomial","SVM.radial","SVM.sigmoid", "NeuralNet")
errores
errores %>%
filter(raiz.error.cuadratico == min(errores$raiz.error.cuadratico))
library(plotly)
install.packages("plotly")
library(plotly)
Datos <- data.frame ( x = c(1 , 1 , 1 , 3 , 1 , 3 , 1 , 3 , 1) ,y = c(0 , 0 , 1 , 1 , 1 , 2 , 2 , 2 , 1) , z = c(1 , 2 , 2 , 4 , 3 , 3 , 1 , 1 , 0) ,clase = c(" Rojo ", " Rojo ", " Rojo "," Rojo ", " Rojo ", " Azul "," Azul ", " Azul ", " Azul "))
plot_ly(data = Datos) %>% add_trace ( x = ~x , y = ~y , z = ~z , color = ~clase , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d")
Datos2 <- data.frame ( x = c(1 , 1 , 3 ) ,y = c(0 , 1 , 1 ) , z = c(1 , 2 , 4 ))
Datos3 <- data.frame ( x = c(1 , 1 , 3 ) ,y = c(1 , 2 , 2 ) , z = c(0 , 1 , 3 ))
Datos4<-data.frame ( x = c(1 , 1 , 3 ) ,y = c(0.5 , 1.5 , 1.5 ) , z = c(0.5 , 1.5 , 3.5 ))
plot_ly(data = Datos) %>% add_trace ( x = ~x , y = ~y , z = ~z , color = ~clase , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d") %>% add_trace(data = Datos2, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d",showlegend=FALSE) %>% add_trace(data = Datos3, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE) %>% add_trace(data = Datos4, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE)
library(pracma)
install.packages("pracma")
library(pracma)
vector.cross <- function(a, b) {
return (cross(a,b))
}
p<-c(1 , 0.5 , 0.5)
q<- c(1 , 1.5 , 1.5 )
r<-c(3 , 1.5 , 3.5 )
pq<-q-p
pr<-r-p
vector.cross(pq, pr)
#El margen para el hiperplano optimo es de 1.
#Los vectores de soporte serian:
vector1 <- cross(c(1 , 1 , 3 ) , c(0 , 1 , 1 ))
vector1
vector2 <- cross(c(1 , 2 , 2 )  , c(0 , 1 , 3 ))
vector2
Datos4<-data.frame ( x = c(1 , 1 , 3 ) ,y = c(0 , 1 , 1 ) , z = c(0.5 , 1.5 , 3.5 ))
plot_ly(data = Datos) %>% add_trace ( x = ~x , y = ~y , z = ~z , color = ~clase , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d") %>% add_trace(data = Datos2, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d",showlegend=FALSE) %>% add_trace(data = Datos3, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE) %>% add_trace(data = Datos4, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE)
p<-c(1 , 0 , 0.5 )
q<- c(1, 1 , 1.5 )
r<-c(3 , 1 , 3.5 )
pq<-q-p
pr<-r-q
vector.cross(pq, pr)
Datos4<-data.frame ( x = c(0 , 0 , 2 ) ,y = c( 0.1, 1.1 , 1.1 ) , z = c(0.5 , 1.5 , 3.5 ))
plot_ly(data = Datos) %>% add_trace ( x = ~x , y = ~y , z = ~z , color = ~clase , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d") %>% add_trace(data = Datos2, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d",showlegend=FALSE) %>% add_trace(data = Datos3, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE) %>% add_trace(data = Datos4, x = ~x , y = ~y , z = ~z ,  mode = 'lines', type = "scatter3d" ,   showlegend=FALSE)
p<-c(0 , 0.1 , 0.5 )
q<- c( 0, 1.1 , 1.5 )
r<-c(2 , 1.1 , 3.5 )
pq<-q-p
pr<-r-p
vector.cross(pq, pr)
Datos <- data.frame ( x = c(1 , 1 , 1 , 3 , 1 , 3 , 1 , 3 , 1, 2) ,y = c(0 , 0 , 1 , 1 , 1 , 2 , 2 , 2 , 1, 4) , z = c(1 , 2 , 2 , 4 , 3 , 3 , 1 , 1 , 0, 2) ,clase = c(" Rojo ", " Rojo ", " Rojo "," Rojo ", " Rojo ", " Azul "," Azul ", " Azul ", " Azul "," Rojo "))
plot_ly(data = Datos) %>% add_trace ( x = ~x , y = ~y , z = ~z , color = ~clase , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d")
3 * x^4 -16 * x^3 + 18 * x^2
funcion <- function(x){
3 * x^4 -16 * x^3 + 18 * x^2
}
t1 <- vector(-5.0,5.0,0.1)
t1 <- vector(-5.0,5.0,0.1)
t1 <- c(-5.0,5.0,0.1)
y = funcion(0)
y = funcion(x)
x = 2.0
y = funcion(x)
plot()x,y
plot(x,y)
curve(funcion, from = t1[1], to = t1[2])
plot(funcion, from = t1[1], to = t1[2])
plot(funcion, from = t1[1], to = t1[2], cex.lab = 3.5, cex.axis = 3.5)
plot(funcion, from = t1[1], to = t1[2])
ggplot()+xlim(-5.0,5.0)
+ylim(-45,45)
+ylim(-45,45)
ggplot()+xlim(-5.0,5.0)+ylim(-45,45)
ggplot()+xlim(-5.0,5.0)+ylim(-45,45)+ geom_function(funcion)
ggplot()+xlim(-5.0,5.0)+ylim(-45,45)+ geom_function(fun = funcion)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
theme_minimal(())
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
theme_minimal()
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(x=x,y=y)
funcion <- function(x){
3 * x^4 -16 * x^3 + 18 * x^2
}
t1 <- c(-5.0,5.0,0.1)
x = 2.0
y = funcion(x)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(x=x,y=y)
theme_minimal()
funcion <- function(x){
3 * x^4 -16 * x^3 + 18 * x^2
}
t1 <- c(-5.0,5.0,0.1)
x = 2.0
y = funcion(x)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(x=x,y=y)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(x=x,y=y)+
theme_minimal()
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(aes(x=x,y=y), colour = "red")+
theme_minimal()
derivada <- function(x){
12*x^3 - 48*x^2 + 36*x
}
pendiente <- derivada(x)
x[2]<- x-eta*pendiente
x - eta*pendiente
eta = 0.5
x[2]<- x - eta*pendiente
x
y[2] <- funcion(x[2])
y
pendiente <- derivada(x)
pendiente
funcion <- function(x){
3 * x^4 -16 * x^3 + 18 * x^2
}
t1 <- c(-5.0,5.0,0.1)
x = 2.0
y = funcion(x)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(aes(x=x,y=y), colour = "red")+
theme_minimal()
x - eta*pendiente
funcion <- function(x){
3 * x^4 -16 * x^3 + 18 * x^2
}
t1 <- c(-5.0,5.0,0.1)
x = 2.0
y = funcion(x)
ggplot()+
xlim(-5.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(aes(x=x,y=y), colour = "red")+
theme_minimal()
x - eta*pendiente
x
eta*pendiente
pendiente
derivada <- function(x){
12*x^3 - 48*x^2 + 36*x
}
derivada(x)
derivada <- function(x){
12*x^3 - 48*x^2 + 36*x
}
pendiente <- derivada(x)
pendiente
eta = 0.5
eta
x - eta*pendiente
x
eta*pendiente
eta = 0.05
x[2]<- x - eta*pendiente
x
y[2] <- funcion(x[2])
y
ggplot()+
xlim(-1.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(aes(x=x[2],y=y[2]), colour = "red")+
theme_minimal()
ggplot()+
xlim(-1.0,5.0)+
ylim(-45,45)+
geom_function(fun = funcion)+
geom_point(aes(x=x,y=y), colour = "red")+
theme_minimal()
funcion <- function(x,y){
x^2 + y^2 - 2*x - 6*y + 14
}
x = -5
y = 5
x0 = c(x,y)
fx0 <- funcion(x,y)
fx0
gradiente <- funcion(x,y){
gradiente <- function(x,y){
c(2*x -2 , 2*y -2)
}
x1 = x0 - eta * gradiente(x0[1],x0[2])
x1
funcion <- function(x,y){
x^2 + y^2 - 2*x - 6*y + 14
}
x = -5
y = 5
x0 = c(x,y)
x0
fx0 <- funcion(x,y)
fx0
gradiente <- function(x,y){
c(2*x -2 , 2*y -2)
}
eta = 0.1
x1 = x0 - eta * gradiente(x0[1],x0[2])
print("x, y :", x1, "\tz: ",f(x1[0],x1[1]), "\n")
x1
x0
fx0
gradiente(x0[1],x0[2])
x1 = x0 - eta * gradiente(x,y)
x1
gradiente(x,y)
fx0
gradiente_f <- gradiente(x0)
gradiente_f <- gradiente(x0[1],x0[2])
gradiente_f
x1 = x0 - eta * gradiente(-5,5)
x1
gradiente_f <- gradiente(-5,5)
gradiente_f
c(2*x -2 , 2*y -6)
gradiente <- function(x,y){
c(2*x -2 , 2*y -6)
}
gradiente_f <- gradiente(-5,5)
gradiente_f
eta = 0.1
x1 = x0 - eta * gradiente(-5,5)
x1
z = funcion(x,y)
z
funcion <- function(x,y){
x^2 + y^2 - 2*x - 6*y + 14
}
x = -5
y = 5
x0 = c(x,y)
x0
fx0 <- funcion(x,y)
fx0
gradiente <- function(x,y){
c(2*x -2 , 2*y -6)
}
gradiente_f <- gradiente(-5,5)
gradiente_f
eta = 0.1
x1 = x0 - eta * gradiente(-5,5)
x1
z = funcion(x,y)
z
print("x, y :", x1, "\tz: ",f(x1[0],x1[1]), "\n")
z
funcion <- function(x,y){
x^2 + y^2 - 2*x - 6*y + 14
}
z = funcion(x,y)
z
z = funcion(x1[1],x1[2])
z
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d")
xi = c(x,y)
append(x, 3)
for(i in c(1,2)){
xi = xi -eta * gradiente(xi[1],xi[2])
x = append(x,xi[1])
y= append(y,xi[2])
z = append(z, funcion(xi[1],xi[2]))
}
x
y
z
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10,0.1))
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10))
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10),ylim(-10,10))
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10),ylim(-10,10),zlim(0,300))
plot_ly() %>% add_trace ( x = ~x , y = ~y , z = ~z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10),ylim(-10,10))
plot_ly() %>% add_trace ( x = ~x[2] , y = ~y[2] , z = ~z[2] , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10),ylim(-10,10))
funcion <- function(x,y){
x^4 + y^4 - 4*x*y + 1
}
x = -0.5
y = 0.5
x0 = c(x,y)
x0
fx0 <- funcion(x,y)
fx0
gradiente <- function(x,y){
c(4*x^3 - 4*y , 4*y^3 - 4*x)
}
gradiente_f <- gradiente(-5,5)
gradiente_f <- gradiente(x,y)
gradiente_f
eta = 0.1
x1 = x0 - eta * gradiente(x,y)
x1
z = funcion(x1[1],x1[2])
z
xi = c(x,y)
for(i in c(1,2)){
xi = xi -eta * gradiente(xi[1],xi[2])
x = append(x,xi[1])
y= append(y,xi[2])
z = append(z, funcion(xi[1],xi[2]))
}
x
y
z
x[2]
y[2]
z[2]
data = data.frame(x=x,y=y,z=z)
plot_ly() %>% add_trace (data = data, x = x , y = y , z = z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "scatter3d", xlim(-10,10),ylim(-10,10))
plot_ly() %>% add_trace (data = data, x = x , y = y , z = z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "mesh3d", xlim(-10,10),ylim(-10,10))
data = data.frame(x=seq(-3,3,by=0.05),y=y,z=z)
seq(-3,3,by=0.05)
data = data.frame(x=seq(-3,3,by=0.05),y=seq(-3,3,0.05),z=funcion(seq(-3,3,by=0.05),seq(-3,3,by=0.05)))
data
plot_ly() %>% add_trace (data = data, x = x , y = y , z = z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "mesh3d")
plot_ly() %>% add_trace (data = data, x = data$x , y=  data$y  , z = data$z , colors = c("#0C4B8E", "#BF382A") , mode = "markers", type = "mesh3d")
